{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ8823vhAPtv",
        "outputId": "0eb1439a-6b44-4a77-ad03-2a6ab67c1703"
      },
      "id": "BQ8823vhAPtv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b88856",
      "metadata": {
        "id": "c3b88856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "811143b4-7520-4ca7-fe06-8bea59b0c3a5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'cleaned_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fade9ae387c1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cleaned_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Define the starting year (adjust this based on the dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cleaned_data.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, Attention, GRU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------- #\n",
        "# Load and Preprocess Training Data\n",
        "# ------------------------------- #\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Define the starting year (adjust this based on the dataset)\n",
        "base_year = 2010  # If Year 1 corresponds to 2016\n",
        "\n",
        "# Convert Year values\n",
        "df['Year'] = df['Year'] + base_year\n",
        "\n",
        "# Ensure Month and Day are correctly formatted\n",
        "df['Month'] = df['Month'].astype(str).str.zfill(2)\n",
        "df['Day'] = df['Day'].astype(str).str.zfill(2)\n",
        "\n",
        "# Convert to proper datetime format\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
        "\n",
        "print(df.head())  # Check the output\n",
        "\n",
        "\n",
        "# Convert Year, Month, Day to datetime\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
        "\n",
        "# Sort by date\n",
        "df = df.sort_values(by='date').reset_index(drop=True)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df.drop(columns=['date']))\n",
        "\n",
        "# Convert to DataFrame\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=df.columns[1:])\n",
        "\n",
        "# ------------------------------- #\n",
        "# Create Time Series Sequences\n",
        "# ------------------------------- #\n",
        "TIME_STEPS = 30   # Past 30 days as input\n",
        "PREDICT_HORIZON = 1  # Predicting 1 day ahead\n",
        "\n",
        "def create_sequences(data, time_steps=TIME_STEPS, predict_horizon=PREDICT_HORIZON):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps - predict_horizon):\n",
        "        X.append(data.iloc[i: i + time_steps].values)\n",
        "        y.append(data.iloc[i + time_steps + predict_horizon - 1, 0])  # Predicting Avg_Temperature\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Create sequences\n",
        "X, y = create_sequences(scaled_df)\n",
        "\n",
        "# Train-test split\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AFTER CHANGING BY ISITHA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, Attention, Concatenate, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Sorting\n",
        "df.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "# One-hot Encoding\n",
        "df = pd.get_dummies(df, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "# Select Features & Targets\n",
        "X = df[['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "Y = df[['Avg_Temperature','Radiation', 'Rain_Amount','Wind_Speed', 'Wind_Direction']].values\n",
        "\n",
        "# Normalize Features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Prepare Sequential Data\n",
        "time_steps = 30\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "for i in range(len(X) - time_steps):\n",
        "    X_seq.append(X[i:i+time_steps])\n",
        "    Y_seq.append(Y[i+time_steps])\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "Y_seq = np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]"
      ],
      "metadata": {
        "id": "rooNCjfAvWsu"
      },
      "id": "rooNCjfAvWsu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------- #\n",
        "# Build CNN-LSTM-Attention Model\n",
        "# ------------------------------- #\n",
        "\n",
        "# Define model input\n",
        "input_layer = Input(shape=(TIME_STEPS, X_train.shape[2]))\n",
        "\n",
        "# CNN Layers\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "flatten = Flatten()(pool2)\n",
        "\n",
        "# LSTM Layer\n",
        "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
        "\n",
        "# Attention Layer\n",
        "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
        "attention_output = Flatten()(attention_layer)\n",
        "\n",
        "# Merge CNN and LSTM outputs\n",
        "merged = tf.keras.layers.Concatenate()([flatten, attention_output])\n",
        "\n",
        "# Dense Layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(1)(dense2)  # Predicting Avg_Temperature\n",
        "\n",
        "# Build Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "F4zc8hIigasV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "e23e771e-f042-407c-ede2-9c51a670dd48"
      },
      "id": "F4zc8hIigasV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m6,208\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │         \u001b[38;5;34m16,600\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention (\u001b[38;5;33mAttention\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1724\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m110,400\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,600</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1724</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110,400</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m141,497\u001b[0m (552.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,497</span> (552.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m141,497\u001b[0m (552.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,497</span> (552.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------- #\n",
        "# Build CNN-GRU-Attention Model\n",
        "# ------------------------------- #\n",
        "\n",
        "# Define model input\n",
        "input_layer = Input(shape=(TIME_STEPS, X_train.shape[2]))\n",
        "\n",
        "# CNN Layers\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "flatten = Flatten()(pool2)\n",
        "\n",
        "# GRU Layer\n",
        "gru_layer = GRU(50, return_sequences=True)(input_layer)\n",
        "\n",
        "# Attention Layer\n",
        "attention_layer = Attention()([gru_layer, gru_layer])\n",
        "attention_output = Flatten()(attention_layer)\n",
        "\n",
        "# Merge CNN and GRU outputs\n",
        "merged = tf.keras.layers.Concatenate()([flatten, attention_output])\n",
        "\n",
        "# Dense Layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(1)(dense2)  # Predicting Avg_Temperature\n",
        "\n",
        "# Build Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "aAQlVqTyglE8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "c31714c2-c896-4485-b927-7d537fd86394"
      },
      "id": "aAQlVqTyglE8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m6,208\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │         \u001b[38;5;34m12,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention_1 (\u001b[38;5;33mAttention\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ attention_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1724\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m110,400\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1724</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110,400</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,497\u001b[0m (537.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,497</span> (537.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m137,497\u001b[0m (537.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,497</span> (537.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011a6477",
      "metadata": {
        "id": "011a6477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a6f3642e-a088-4e55-b945-497421bc296b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m 180/2124\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 65ms/step - loss: 8684.2090 - mae: 61.7630"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-394f7c06a190>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Train the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ------------------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Plot Training Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ------------------------------- #\n",
        "# Train the Model\n",
        "# ------------------------------- #\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Prepare Test Data for Prediction\n",
        "# ------------------------------- #\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv(\"../test.csv\")\n",
        "\n",
        "# Convert Year, Month, Day to datetime\n",
        "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "test_df = test_df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
        "\n",
        "# Merge with last known training data (to get missing feature values)\n",
        "last_train_data = df[df['date'] <= test_df['date'].min()]  # Get last available data\n",
        "test_df = test_df.merge(last_train_data, on='date', how='left')\n",
        "\n",
        "# Fill missing values using forward fill\n",
        "test_df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Normalize test data\n",
        "scaled_test_data = scaler.transform(test_df.drop(columns=['date']))\n",
        "\n",
        "# Convert test data into sequences\n",
        "X_test_seq, _ = create_sequences(pd.DataFrame(scaled_test_data, columns=test_df.columns[1:]))\n",
        "\n",
        "# ------------------------------- #\n",
        "# Make Predictions\n",
        "# ------------------------------- #\n",
        "predictions = model.predict(X_test_seq)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "predicted_temp = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Save predictions\n",
        "test_df['Predicted_Temperature'] = predicted_temp\n",
        "test_df.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
        "\n",
        "\n",
        "# Define the starting year (adjust this based on the dataset)\n",
        "base_year = 2010  # If Year 1 corresponds to 2016\n",
        "\n",
        "# Convert Year values\n",
        "test_df['Year'] = test_df['Year'] + base_year\n",
        "\n",
        "# Ensure Month and Day are correctly formatted\n",
        "test_df['Month'] = test_df['Month'].astype(str).str.zfill(2)\n",
        "test_df['Day'] = test_df['Day'].astype(str).str.zfill(2)\n",
        "\n",
        "# Convert to proper datetime format\n",
        "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
        "\n",
        "print(test_df.head())  # Check the output\n",
        "\n",
        "# Convert Year, Month, Day to datetime\n",
        "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "test_df = test_df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
        "\n",
        "# Merge with last known training data (to get missing feature values)\n",
        "last_train_data = df[df['date'] <= test_df['date'].min()]  # Get last available data\n",
        "test_df = test_df.merge(last_train_data, on='date', how='left')\n",
        "\n",
        "# Fill missing values using forward fill\n",
        "test_df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Normalize test data\n",
        "scaled_test_data = scaler.transform(test_df.drop(columns=['date']))\n",
        "\n",
        "# Convert test data into sequences\n",
        "X_test_seq, _ = create_sequences(pd.DataFrame(scaled_test_data, columns=test_df.columns[1:]))\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------- #\n",
        "# Make Predictions\n",
        "# ------------------------------- #\n",
        "predictions = model.predict(X_test_seq)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "predicted_temp = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Save predictions\n",
        "test_df['Predicted_Temperature'] = predicted_temp\n",
        "test_df.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved successfully!\")"
      ],
      "metadata": {
        "id": "xKf7jPzhg1xn"
      },
      "id": "xKf7jPzhg1xn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2dbbecc",
      "metadata": {
        "id": "b2dbbecc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming you already have your trained model and scaler\n",
        "# Load the test data\n",
        "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
        "\n",
        "# Map the Year column (1-8) to actual years (e.g., 2016 to 2023)\n",
        "base_year = 2015  # If Year 1 corresponds to 2016\n",
        "test_df['Year'] = test_df['Year'] + base_year\n",
        "\n",
        "# Ensure Month and Day are in proper format\n",
        "test_df['Month'] = test_df['Month'].astype(str).str.zfill(2)\n",
        "test_df['Day'] = test_df['Day'].astype(str).str.zfill(2)\n",
        "\n",
        "# Create the date column\n",
        "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
        "\n",
        "# Drop unnecessary columns (those not used for prediction)\n",
        "test_df = test_df.drop(columns=['ID', 'Year', 'Month', 'Day', 'kingdom', 'date'])\n",
        "\n",
        "# Ensure columns in the test data match those in the training data\n",
        "required_columns = ['Avg_Temperature', 'Avg_Feels_Like_Temperature', 'Temperature_Range',\n",
        "                    'Feels_Like_Temperature_Range', 'Radiation', 'Rain_Amount', 'Rain_Duration',\n",
        "                    'Wind_Speed', 'Wind_Direction', 'Evapotranspiration']  # Add the exact list from training\n",
        "missing_columns = [col for col in required_columns if col not in test_df.columns]\n",
        "\n",
        "if missing_columns:\n",
        "    raise ValueError(f\"Missing columns in test data: {missing_columns}\")\n",
        "\n",
        "# Check for extra columns in test data\n",
        "extra_columns = [col for col in test_df.columns if col not in required_columns]\n",
        "if extra_columns:\n",
        "    print(f\"Warning: Extra columns in test data that are not used for prediction: {extra_columns}\")\n",
        "    test_df = test_df[required_columns]  # Remove extra columns\n",
        "\n",
        "# Normalize the test data using the same scaler used during training\n",
        "scaled_test_data = scaler.transform(test_df)\n",
        "\n",
        "# Convert test data into sequences (same as for training)\n",
        "X_test_seq, _ = create_sequences(pd.DataFrame(scaled_test_data, columns=test_df.columns))\n",
        "\n",
        "# Predict using the trained model\n",
        "predictions = model.predict(X_test_seq)\n",
        "\n",
        "# If you need to inverse the scaling\n",
        "predicted_values = scaler.inverse_transform(predictions)\n",
        "\n",
        "# You can extract the predicted values for each of the variables\n",
        "predicted_temp = predicted_values[:, 0]  # Assuming temperature is the first column in your predictions\n",
        "\n",
        "# Adding predictions to the test DataFrame (you can add other variables similarly)\n",
        "test_df['Predicted_Temperature'] = predicted_temp\n",
        "\n",
        "# Optionally, save the predictions to a CSV\n",
        "test_df.to_csv('predictions.csv', index=False)\n",
        "\n",
        "# Print the first few rows of the predictions\n",
        "print(test_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding corelations in the dataset"
      ],
      "metadata": {
        "id": "q-ObNGiHLiKQ"
      },
      "id": "q-ObNGiHLiKQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "data = pd.read_csv('./train.csv')  # Replace with the actual path to your data file\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Basic statistics of the dataset\n",
        "print(\"\\nBasic statistics of the dataset:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in the dataset:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "def kelvin_to_celsius(kelvin_temp):\n",
        "    \"\"\"Converts temperature in Kelvin to Celsius.\n",
        "    Args:\n",
        "        kelvin_temp: Temperature in Kelvin.\n",
        "    Returns:\n",
        "        Temperature in Celsius.\n",
        "    \"\"\"\n",
        "    celsius_temp = kelvin_temp - 273.15\n",
        "    return celsius_temp\n",
        "\n",
        "# Assume 'df' is your DataFrame and 'Avg_Temperature' is the column\n",
        "# Replace outlier_condition with your logic to identify Kelvin values\n",
        "data['Avg_Temperature'] = np.where(data['Avg_Temperature'] > 270,\n",
        "                                      data['Avg_Temperature'].apply(kelvin_to_celsius),\n",
        "                                      data['Avg_Temperature'])\n",
        "\n",
        "# Visualize the distribution of Avg_Temperature\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Avg_Temperature'], kde=True, color='blue')\n",
        "plt.title('Distribution of Avg_Temperature')\n",
        "plt.xlabel('Avg_Temperature')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Visualize the distribution of Radiation\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Radiation'], kde=True, color='blue')\n",
        "plt.title('Distribution of Radiation')\n",
        "plt.xlabel('Radiation')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Visualize the distribution of Rain_Amount\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Rain_Amount'], kde=True, color='blue')\n",
        "plt.title('Distribution of Rain_Amount')\n",
        "plt.xlabel('Rain_Amount')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Visualize the distribution of Wind_Speed\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Wind_Speed'], kde=True, color='blue')\n",
        "plt.title('Distribution of Wind_Speed')\n",
        "plt.xlabel('Wind_Speed')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Visualize the distribution of Wind_Direction\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Wind_Direction'], kde=True, color='blue')\n",
        "plt.title('Distribution of Wind_Direction')\n",
        "plt.xlabel('Wind_Direction')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Scatter plot for Avg_Temperature vs Radiation\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Avg_Temperature', y='Radiation', hue='kingdom', data=data)\n",
        "plt.title('Avg_Temperature vs Radiation')\n",
        "plt.xlabel('Avg_Temperature')\n",
        "plt.ylabel('Radiation')\n",
        "plt.legend(title='Kingdom')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Select only numeric columns for correlation\n",
        "numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
        "correlation_matrix = numeric_data.corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Boxplot for Avg_Temperature by Kingdom\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='kingdom', y='Avg_Temperature', data=data)\n",
        "plt.title('Avg_Temperature by Kingdom')\n",
        "plt.xlabel('Kingdom')\n",
        "plt.ylabel('Avg_Temperature')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Pairplot for selected features\n",
        "selected_features = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed']\n",
        "sns.pairplot(data[selected_features])\n",
        "plt.show()\n",
        "\n",
        "data.hist(bins=50, figsize=(12, 8))\n",
        "plt.show()\n",
        "\n",
        "data.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", grid=True,\n",
        "s=data[\"Avg_Temperature\"]/100 , label=\"temperature\" ,c=data[\"Avg_Temperature\"], cmap=\"jet\", colorbar=True,legend=True, sharex=False, figsize=(10, 7))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J-soORyuLkF6",
        "outputId": "1f6e67ad-df54-41f8-aa1f-7ebf68b50acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "id": "J-soORyuLkF6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0b3008062443>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the data into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with the actual path to your data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Display the first few rows of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "905316d6",
      "metadata": {
        "id": "905316d6"
      },
      "outputs": [],
      "source": [
        "data.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", grid=True,\n",
        "s=data[\"Avg_Temperature\"] , label=\"temperature\" ,c=data[\"Avg_Temperature\"], cmap=\"jet\", colorbar=True,legend=True, sharex=False, figsize=(10, 7))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('cleaned_data.csv', index=False)\n",
        "print(\"\\nCleaned data saved to 'cleaned_data.csv'\")"
      ],
      "metadata": {
        "id": "ekWPojZvVPef"
      },
      "id": "ekWPojZvVPef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3# prompt: Write me a code to generate time series graphs for each kingdom using python and matplotlib\n",
        "# Date is in 3 columns as (Year         Month           Day)\n",
        "# I said there isn't a column called Date. instead of it there are three columns as year, month, day\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"cleaned_data.csv\")  # Replace with your actual file path\n",
        "\n",
        "# Convert Year, Month, Day to datetime\n",
        "# Convert Year, Month, Day to datetime\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
        "# Group data by kingdom and date\n",
        "\n",
        "kingdom_groups = df.groupby('kingdom')\n",
        "\n",
        "# Iterate through each kingdom\n",
        "for kingdom, data in kingdom_groups:\n",
        "    # Sort the data by date\n",
        "\n",
        "    data = data.sort_values(by='date')\n",
        "\n",
        "    # Plot the time series for Avg_Temperature\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(data['date'], data['Rain_Duration'])\n",
        "    plt.title(f'Average Temperature over Time for Kingdom: {kingdom}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Average Temperature')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "8oKH9FB7VQwv"
      },
      "id": "8oKH9FB7VQwv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, Attention, Concatenate, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Sorting\n",
        "df.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "# One-hot Encoding\n",
        "df = pd.get_dummies(df, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "# Select Features & Targets\n",
        "X = df[['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "Y = df[['Avg_Temperature','Radiation', 'Rain_Amount','Wind_Speed', 'Wind_Direction']].values\n",
        "\n",
        "# Normalize Features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Prepare Sequential Data\n",
        "time_steps = 30\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "for i in range(len(X) - time_steps):\n",
        "    X_seq.append(X[i:i+time_steps])\n",
        "    Y_seq.append(Y[i+time_steps])\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "Y_seq = np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# ------------------------------- #\n",
        "# Build CNN-LSTM-Attention Model\n",
        "# ------------------------------- #\n",
        "\n",
        "# Model Input\n",
        "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "\n",
        "# CNN Layers\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "cnn_output = Flatten()(pool2)\n",
        "\n",
        "# LSTM Layer\n",
        "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
        "\n",
        "# Attention Layer\n",
        "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
        "attention_output = GlobalAveragePooling1D()(attention_layer)\n",
        "\n",
        "# Merge CNN and LSTM outputs\n",
        "merged = Concatenate()([cnn_output, attention_output])\n",
        "\n",
        "# Dense Layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(5)(dense2)  # Predicting 5 variables\n",
        "\n",
        "# Build Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Train the Model\n",
        "# ------------------------------- #\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yMMbUMqIm28e"
      },
      "id": "yMMbUMqIm28e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Sorting\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "# One-hot Encoding\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)  # This removes the 'kingdom' column\n",
        "\n",
        "# Define Time Steps\n",
        "time_steps = 30\n",
        "\n",
        "# Store sequences\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "# Group by Kingdom using df1 (original)\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    # Get corresponding rows from df (one-hot encoded)\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']].values\n",
        "\n",
        "    # Normalize Features\n",
        "    scaler_X = MinMaxScaler()\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "\n",
        "    scaler_Y = MinMaxScaler()\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    # Generate Time-Series Sequences for This Kingdom\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_seq = np.array(X_seq)\n",
        "Y_seq = np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# Print Shape for Debugging\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "\n",
        "# ------------------------------- #\n",
        "# Build CNN-LSTM-Attention Model\n",
        "# ------------------------------- #\n",
        "\n",
        "# Model Input\n",
        "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "\n",
        "# CNN Layers\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "cnn_output = Flatten()(pool2)\n",
        "\n",
        "# LSTM Layer\n",
        "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
        "\n",
        "# Attention Layer\n",
        "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
        "attention_output = GlobalAveragePooling1D()(attention_layer)\n",
        "\n",
        "# Merge CNN and LSTM outputs\n",
        "merged = Concatenate()([cnn_output, attention_output])\n",
        "\n",
        "# Dense Layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(5)(dense2)  # Predicting 5 variables\n",
        "\n",
        "# Build Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Train the Model\n",
        "# ------------------------------- #\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ry_RVBd874d5"
      },
      "id": "Ry_RVBd874d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Sorting\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "# One-hot Encoding\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)  # This removes the 'kingdom' column\n",
        "\n",
        "# Define Time Steps\n",
        "time_steps = 30\n",
        "\n",
        "# Store sequences\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "# Group by Kingdom using df1 (original)\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    # Get corresponding rows from df (one-hot encoded)\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']].values\n",
        "\n",
        "    # Normalize Features\n",
        "    scaler_X = MinMaxScaler()\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "\n",
        "    scaler_Y = MinMaxScaler()\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    # Generate Time-Series Sequences for This Kingdom\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_seq = np.array(X_seq)\n",
        "Y_seq = np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# Print Shape for Debugging\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "\n",
        "# ------------------------------- #\n",
        "# Build CNN-GRU-Attention Model\n",
        "# ------------------------------- #\n",
        "\n",
        "# Define model input\n",
        "input_layer = Input(shape=(TIME_STEPS, X_train.shape[2]))\n",
        "\n",
        "# CNN Layers\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "flatten = Flatten()(pool2)\n",
        "\n",
        "# GRU Layer\n",
        "gru_layer = GRU(50, return_sequences=True)(input_layer)\n",
        "\n",
        "# Attention Layer\n",
        "attention_layer = Attention()([gru_layer, gru_layer])\n",
        "attention_output = Flatten()(attention_layer)\n",
        "\n",
        "# Merge CNN and GRU outputs\n",
        "merged = tf.keras.layers.Concatenate()([flatten, attention_output])\n",
        "\n",
        "# Dense Layers\n",
        "dense1 = Dense(64, activation='relu')(merged)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(1)(dense2)  # Predicting Avg_Temperature\n",
        "\n",
        "# Build Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Train the Model\n",
        "# ------------------------------- #\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vAyL901mtZSB"
      },
      "id": "vAyL901mtZSB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Sorting\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "# One-hot Encoding\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)  # This removes the 'kingdom' column\n",
        "\n",
        "# Define Time Steps\n",
        "time_steps = 30\n",
        "\n",
        "# Store sequences\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "# Group by Kingdom using df1 (original)\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    # Get corresponding rows from df (one-hot encoded)\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']].values\n",
        "\n",
        "    # Normalize Features\n",
        "    scaler_X = MinMaxScaler()\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "\n",
        "    scaler_Y = MinMaxScaler()\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    # Generate Time-Series Sequences for This Kingdom\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_seq = np.array(X_seq)\n",
        "Y_seq = np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# Print Shape for Debugging\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "\n",
        "# ------------------------------- #\n",
        "# Build Transformer Model\n",
        "# ------------------------------- #\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    # Attention layer\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
        "    attn_output = tf.keras.layers.Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)  # Skip Connection\n",
        "\n",
        "    # Feed-Forward Network\n",
        "    ff_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ff_output = tf.keras.layers.Dense(inputs.shape[-1])(ff_output)  # Output size matching input\n",
        "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
        "\n",
        "\n",
        "# Model Input\n",
        "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "\n",
        "# CNN Layers\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "\n",
        "# Calculate the new time dimension after pooling\n",
        "new_time_steps = time_steps // 2  # 30 / 2 = 15\n",
        "\n",
        "# Reshaping to match transformer input shape (batch_size, time_steps, feature_size)\n",
        "transformer_input = tf.keras.layers.Reshape((new_time_steps, conv2.shape[-1]))(conv2)\n",
        "\n",
        "# Transformer Encoder\n",
        "transformer_output = transformer_encoder(transformer_input, head_size=64, num_heads=4, ff_dim=128)\n",
        "\n",
        "# Flatten the transformer output\n",
        "flatten = Flatten()(transformer_output)\n",
        "\n",
        "# Dense Layers\n",
        "dense1 = Dense(64, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(5)(dense2)  # Adjusted to match y_train.shape[-1]\n",
        "\n",
        "# Build and compile the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Train the Model\n",
        "# ------------------------------- #\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z0nPyZbtOCUT"
      },
      "id": "z0nPyZbtOCUT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgGduE8eSSMb"
      },
      "id": "VgGduE8eSSMb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Attention, Dense, Dropout, Flatten, GlobalAveragePooling1D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Sorting\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "# One-hot Encoding\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "# Define Time Steps\n",
        "time_steps = 30\n",
        "\n",
        "# Store sequences and data for Decision Trees\n",
        "X_seq, Y_seq = [], []\n",
        "X_dt_dict, Y_dt_dict = {}, {}  # Dictionary to store data per kingdom for Decision Trees\n",
        "\n",
        "# Group by Kingdom\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    # Get corresponding rows from df (one-hot encoded)\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']].values\n",
        "\n",
        "    # Normalize Features\n",
        "    scaler_X = MinMaxScaler()\n",
        "    group_X_scaled = scaler_X.fit_transform(group_X)\n",
        "\n",
        "    scaler_Y = MinMaxScaler()\n",
        "    group_Y_scaled = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    # Generate Time-Series Sequences for CNN-LSTM-Attention\n",
        "    for i in range(len(group_X_scaled) - time_steps):\n",
        "        X_seq.append(group_X_scaled[i:i+time_steps])\n",
        "        Y_seq.append(group_Y_scaled[i+time_steps])\n",
        "\n",
        "    # Store data for Decision Tree (no sequences, just flat data)\n",
        "    X_dt_dict[kingdom] = group_X_scaled\n",
        "    Y_dt_dict[kingdom] = group_Y_scaled\n",
        "\n",
        "# Convert to numpy arrays for CNN-LSTM\n",
        "X_seq = np.array(X_seq)\n",
        "Y_seq = np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split for CNN-LSTM\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# Print Shape for Debugging\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# ------------------------------- #\n",
        "# Build Transformer Model\n",
        "# ------------------------------- #\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    # Attention layer\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
        "    attn_output = tf.keras.layers.Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)  # Skip Connection\n",
        "\n",
        "    # Feed-Forward Network\n",
        "    ff_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ff_output = tf.keras.layers.Dense(inputs.shape[-1])(ff_output)  # Output size matching input\n",
        "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
        "\n",
        "\n",
        "# Model Input\n",
        "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "\n",
        "# CNN Layers\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "\n",
        "# Calculate the new time dimension after pooling\n",
        "new_time_steps = time_steps // 2  # 30 / 2 = 15\n",
        "\n",
        "# Reshaping to match transformer input shape (batch_size, time_steps, feature_size)\n",
        "transformer_input = tf.keras.layers.Reshape((new_time_steps, conv2.shape[-1]))(conv2)\n",
        "\n",
        "# Transformer Encoder\n",
        "transformer_output = transformer_encoder(transformer_input, head_size=64, num_heads=4, ff_dim=128)\n",
        "\n",
        "# Flatten the transformer output\n",
        "flatten = Flatten()(transformer_output)\n",
        "\n",
        "# Dense Layers\n",
        "dense1 = Dense(64, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(5)(dense2)  # Adjusted to match y_train.shape[-1]\n",
        "\n",
        "# Build and compile the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Decision Tree Models per Kingdom\n",
        "# ------------------------------- #\n",
        "\n",
        "# Dictionary to store Decision Tree models and their performance\n",
        "dt_models = {}\n",
        "dt_mae_scores = {}\n",
        "\n",
        "for kingdom in X_dt_dict.keys():\n",
        "    # Train-test split for XGBoost (80-20 split)\n",
        "    X_dt = X_dt_dict[kingdom]\n",
        "    Y_dt = Y_dt_dict[kingdom]\n",
        "    split_dt = int(0.8 * len(X_dt))\n",
        "\n",
        "    X_dt_train, X_dt_test = X_dt[:split_dt], X_dt[split_dt:]\n",
        "    y_dt_train, y_dt_test = Y_dt[:split_dt], Y_dt[split_dt:]\n",
        "\n",
        "    # Initialize and train XGBoost Regressor\n",
        "\n",
        "    # xgb_model.fit(X_dt_train, y_dt_train)\n",
        "    history_dt = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "    # Store the model\n",
        "    dt_models[kingdom] = history_dt\n",
        "\n",
        "    # Evaluate the model\n",
        "    # y_dt_pred = xgb_model.predict(X_dt_test)\n",
        "    # mae = np.mean(np.abs(y_dt_test - y_dt_pred))\n",
        "    # xgb_mae_scores[kingdom] = mae\n",
        "    print(f\"XGBoost MAE for {kingdom}: {mae}\")\n",
        "    plt.plot(history.history['loss'], label='Train Loss (CNN-LSTM)')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss (CNN-LSTM)')\n",
        "    plt.legend()\n",
        "    plt.title(f\"CNN-LSTM-Attention Training Loss for {kingdom}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ------------------------------- #\n",
        "# Plot CNN-LSTM-Attention Results\n",
        "# ------------------------------- #\n",
        "\n",
        "# plt.plot(history.history['loss'], label='Train Loss (CNN-LSTM)')\n",
        "# plt.plot(history.history['val_loss'], label='Validation Loss (CNN-LSTM)')\n",
        "# plt.legend()\n",
        "# plt.title(\"CNN-LSTM-Attention Training Loss\")\n",
        "# plt.show()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Compare Results\n",
        "# ------------------------------- #\n",
        "\n",
        "# print(\"\\nCNN-LSTM-Attention Validation MAE:\", history.history['mae'][-1])\n",
        "print(\"Decision Tree MAE Scores per Kingdom:\")\n",
        "for kingdom, mae in xgb_mae_scores.items():\n",
        "    print(f\"{kingdom}: {mae}\")"
      ],
      "metadata": {
        "id": "gYcpxPj0ap5M"
      },
      "id": "gYcpxPj0ap5M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Convert Year, Month, and Day into a Date column (required for Prophet)\n",
        "df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "target_columns = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
        "\n",
        "# Dictionary to store Prophet models and forecasts for each kingdom\n",
        "prophet_models = {}\n",
        "prophet_forecasts = {}\n",
        "\n",
        "# Train a separate Prophet model for each kingdom and each target variable\n",
        "for kingdom, group in df.groupby('kingdom'):\n",
        "    prophet_models[kingdom] = {}\n",
        "    prophet_forecasts[kingdom] = {}\n",
        "\n",
        "    for target in target_columns:\n",
        "        print(f\"Training Prophet model for {kingdom} - {target}...\")\n",
        "\n",
        "        # Prepare data for Prophet (ds: date, y: target variable)\n",
        "        kingdom_df = group[['ds', target]].dropna().rename(columns={target: 'y'})\n",
        "\n",
        "        # Initialize and fit Prophet model\n",
        "        model = Prophet()\n",
        "        model.fit(kingdom_df)\n",
        "\n",
        "        # Create a future dataframe for prediction (next 30 days)\n",
        "        future = model.make_future_dataframe(periods=30)\n",
        "        forecast = model.predict(future)\n",
        "\n",
        "        # Store model and forecast\n",
        "        prophet_models[kingdom][target] = model\n",
        "        prophet_forecasts[kingdom][target] = forecast\n",
        "\n",
        "        # Plot the results\n",
        "        fig = model.plot(forecast)\n",
        "        plt.title(f\"{kingdom} - Forecast for {target}\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "D0Yo3chG6M3o"
      },
      "id": "D0Yo3chG6M3o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_models = {}\n",
        "xgb_mae_scores = {}\n",
        "\n",
        "for kingdom in X_dt_dict.keys():\n",
        "    # Train-test split for XGBoost (80-20 split)\n",
        "    X_dt = X_dt_dict[kingdom]\n",
        "    Y_dt = Y_dt_dict[kingdom]\n",
        "    split_dt = int(0.8 * len(X_dt))\n",
        "\n",
        "    X_dt_train, X_dt_test = X_dt[:split_dt], X_dt[split_dt:]\n",
        "    y_dt_train, y_dt_test = Y_dt[:split_dt], Y_dt[split_dt:]\n",
        "\n",
        "    # Initialize and train XGBoost Regressor\n",
        "    xgb_model = xgb.XGBRegressor(\n",
        "        objective='reg:squarederror',  # For regression tasks\n",
        "        n_estimators=100,              # Number of boosting rounds\n",
        "        learning_rate=0.1,             # Step size shrinkage\n",
        "        max_depth=8,                   # Maximum depth of trees\n",
        "        random_state=42                # For reproducibility\n",
        "    )\n",
        "    xgb_model.fit(X_dt_train, y_dt_train)\n",
        "\n",
        "    # Store the model\n",
        "    xgb_models[kingdom] = xgb_model\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_dt_pred = xgb_model.predict(X_dt_test)\n",
        "    mae = np.mean(np.abs(y_dt_test - y_dt_pred))\n",
        "    xgb_mae_scores[kingdom] = mae\n",
        "    print(f\"XGBoost MAE for {kingdom}: {mae}\")"
      ],
      "metadata": {
        "id": "YqJq5vWjdpRF"
      },
      "id": "YqJq5vWjdpRF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dense, Dropout, Embedding, Flatten, Concatenate, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Sorting\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "# Integer-encode kingdoms\n",
        "le = LabelEncoder()\n",
        "df1['kingdom_id'] = le.fit_transform(df1['kingdom'])\n",
        "n_kingdoms = len(le.classes_)\n",
        "\n",
        "# Define Time Steps\n",
        "time_steps = 30\n",
        "\n",
        "# Store sequences\n",
        "X_seq, kingdom_ids, Y_seq = [], [], []\n",
        "\n",
        "# Group by Kingdom\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    # Get features (excluding kingdom information)\n",
        "    group_X = group[['Year', 'Month', 'Day']].values\n",
        "    group_Y = group[['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']].values\n",
        "    kingdom_id = group['kingdom_id'].iloc[0]\n",
        "\n",
        "    # Normalize Features\n",
        "    scaler_X = MinMaxScaler()\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "\n",
        "    scaler_Y = MinMaxScaler()\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    # Generate sequences\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "        kingdom_ids.append(kingdom_id)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_seq = np.array(X_seq)\n",
        "kingdom_ids = np.array(kingdom_ids)\n",
        "Y_seq = np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "k_train, k_test = kingdom_ids[:split], kingdom_ids[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# ------------------------------- #\n",
        "# Enhanced Kingdom-Aware Transformer Model\n",
        "# ------------------------------- #\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    # Attention layer\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
        "    attn_output = tf.keras.layers.Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
        "\n",
        "    # Feed-Forward Network\n",
        "    ff_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ff_output = tf.keras.layers.Dense(inputs.shape[-1])(ff_output)\n",
        "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
        "\n",
        "# Time-series input\n",
        "ts_input = Input(shape=(time_steps, X_train.shape[2]))\n",
        "\n",
        "# CNN Feature Extraction\n",
        "conv1 = Conv1D(64, 3, activation='relu', padding='same')(ts_input)\n",
        "pool1 = MaxPooling1D(2)(conv1)\n",
        "conv2 = Conv1D(128, 3, activation='relu', padding='same')(pool1)\n",
        "\n",
        "# Transformer Processing\n",
        "new_time_steps = time_steps // 2\n",
        "transformer_input = Reshape((new_time_steps, conv2.shape[-1]))(conv2)\n",
        "transformer_output = transformer_encoder(transformer_input, 64, 4, 128)\n",
        "ts_features = Flatten()(transformer_output)\n",
        "\n",
        "# Kingdom input processing\n",
        "kingdom_input = Input(shape=(1,))\n",
        "kingdom_embedding = Embedding(n_kingdoms, 4)(kingdom_input)\n",
        "kingdom_features = Flatten()(kingdom_embedding)\n",
        "\n",
        "# Combined features\n",
        "combined = Concatenate()([ts_features, kingdom_features])\n",
        "\n",
        "# Prediction head\n",
        "dense1 = Dense(64, activation='relu')(combined)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output = Dense(5)(dense2)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=[ts_input, kingdom_input], outputs=output)\n",
        "model.compile(optimizer=RMSprop(0.001), loss='mse', metrics=['mae'])\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Train the Model\n",
        "# ------------------------------- #\n",
        "history = model.fit(\n",
        "    [X_train, k_train], y_train,\n",
        "    validation_data=([X_test, k_test], y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vVnDWcIhi38s"
      },
      "id": "vVnDWcIhi38s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "# Convert predictions & actual values back to original scale (if you used MinMaxScaler)\n",
        "y_test_original = scaler_Y.inverse_transform(y_test)\n",
        "y_pred_original = scaler_Y.inverse_transform(model.predict([X_test, k_test]))\n",
        "\n",
        "# Compute sMAPE for each target variable\n",
        "smape_values = [smape(y_test_original[:, i], y_pred_original[:, i]) for i in range(y_test_original.shape[1])]\n",
        "\n",
        "# Print sMAPE values for each variable\n",
        "target_columns = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
        "for i, col in enumerate(target_columns):\n",
        "    print(f\"sMAPE for {col}: {smape_values[i]:.2f}%\")\n",
        "\n",
        "# Average sMAPE across all targets\n",
        "average_smape = np.mean(smape_values)\n",
        "print(f\"Overall sMAPE: {average_smape:.2f}%\")"
      ],
      "metadata": {
        "id": "-e6mi7F_q1QC"
      },
      "id": "-e6mi7F_q1QC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the test dataset\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Apply the same preprocessing as the training data\n",
        "test_df.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "test_df = pd.get_dummies(test_df, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "# Ensure all training features exist in test data\n",
        "missing_cols = set(df.columns) - set(test_df.columns)\n",
        "for col in missing_cols:\n",
        "    test_df[col] = 0  # Add missing one-hot encoded columns\n",
        "\n",
        "# Select feature columns (same as training)\n",
        "feature_cols = ['Year', 'Month', 'Day'] + [col for col in test_df.columns if 'kingdom' in col]\n",
        "test_X = test_df[feature_cols].values\n",
        "\n",
        "# Normalize test data using the same scaler\n",
        "test_X = scaler_X.transform(test_X)\n",
        "\n",
        "# Reshape for model input (if sequences are needed)\n",
        "X_test_seq = []\n",
        "for i in range(len(test_X) - time_steps):\n",
        "    X_test_seq.append(test_X[i:i+time_steps])\n",
        "X_test_seq = np.array(X_test_seq)\n",
        "\n",
        "# Predict\n",
        "y_pred_scaled = model.predict(X_test_seq)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "y_pred_original = scaler_Y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "# Save results to CSV\n",
        "output_df = pd.DataFrame(y_pred_original, columns=['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction'])\n",
        "output_df.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved successfully!\")"
      ],
      "metadata": {
        "id": "LUDSEuzbrJ-S"
      },
      "id": "LUDSEuzbrJ-S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Sorting\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "# One-hot Encoding\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)  # This removes the 'kingdom' column\n",
        "\n",
        "# Define Time Steps\n",
        "time_steps = 30\n",
        "\n",
        "# Store sequences\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "# Group by Kingdom using df1 (original)\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    # Get corresponding rows from df (one-hot encoded)\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, [\"Avg_Temperature\",\"Avg_Feels_Like_Temperature\",\"Temperature_Range\",\"Feels_Like_Temperature_Range\",\"Radiation\",\"Rain_Amount\",\"Rain_Duration\",\"Wind_Speed\",\"Wind_Direction\",\"Evapotranspiration\"]].values\n",
        "\n",
        "    # Normalize Features\n",
        "    scaler_X = MinMaxScaler()\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "\n",
        "    scaler_Y = MinMaxScaler()\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    # Generate Time-Series Sequences for This Kingdom\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_seq = np.array(X_seq)\n",
        "Y_seq = np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# Print Shape for Debugging\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "\n",
        "# ------------------------------- #\n",
        "# Build Transformer Model\n",
        "# ------------------------------- #\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    # Attention layer\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
        "    attn_output = tf.keras.layers.Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)  # Skip Connection\n",
        "\n",
        "    # Feed-Forward Network\n",
        "    ff_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ff_output = tf.keras.layers.Dense(inputs.shape[-1])(ff_output)  # Output size matching input\n",
        "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
        "\n",
        "\n",
        "# Model Input\n",
        "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "\n",
        "# CNN Layers\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "\n",
        "# Calculate the new time dimension after pooling\n",
        "new_time_steps = time_steps // 2  # 30 / 2 = 15\n",
        "\n",
        "# Reshaping to match transformer input shape (batch_size, time_steps, feature_size)\n",
        "transformer_input = tf.keras.layers.Reshape((new_time_steps, conv2.shape[-1]))(conv2)\n",
        "\n",
        "# Transformer Encoder\n",
        "transformer_output = transformer_encoder(transformer_input, head_size=64, num_heads=4, ff_dim=128)\n",
        "\n",
        "# Flatten the transformer output\n",
        "flatten = Flatten()(transformer_output)\n",
        "\n",
        "# Dense Layers\n",
        "dense1 = Dense(64, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(10)(dense2)  # Adjusted to match y_train.shape[-1]\n",
        "\n",
        "# Build and compile the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------- #\n",
        "# Train the Model\n",
        "# ------------------------------- #\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "# Convert predictions & actual values back to original scale (if you used MinMaxScaler)\n",
        "y_test_original = scaler_Y.inverse_transform(y_test)\n",
        "y_pred_original = scaler_Y.inverse_transform(model.predict(X_test))\n",
        "\n",
        "# Compute sMAPE for each target variable\n",
        "smape_values = [smape(y_test_original[:, i], y_pred_original[:, i]) for i in range(y_test_original.shape[1])]\n",
        "\n",
        "# Print sMAPE values for each variable\n",
        "target_columns = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
        "for i, col in enumerate(target_columns):\n",
        "    print(f\"sMAPE for {col}: {smape_values[i]:.2f}%\")\n",
        "\n",
        "# Average sMAPE across all targets\n",
        "average_smape = np.mean(smape_values)\n",
        "print(f\"Overall sMAPE: {average_smape:.2f}%\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the test dataset\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Apply the same preprocessing as the training data\n",
        "test_df.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "test_df = pd.get_dummies(test_df, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "# Ensure all training features exist in test data\n",
        "missing_cols = set(df.columns) - set(test_df.columns)\n",
        "for col in missing_cols:\n",
        "    test_df[col] = 0  # Add missing one-hot encoded columns\n",
        "\n",
        "# Select feature columns (same as training)\n",
        "feature_cols = ['Year', 'Month', 'Day'] + [col for col in test_df.columns if 'kingdom' in col]\n",
        "test_X = test_df[feature_cols].values\n",
        "\n",
        "# Normalize test data using the same scaler\n",
        "test_X = scaler_X.transform(test_X)\n",
        "\n",
        "# Reshape for model input (if sequences are needed)\n",
        "X_test_seq = []\n",
        "for i in range(len(test_X) - time_steps):\n",
        "    X_test_seq.append(test_X[i:i+time_steps])\n",
        "X_test_seq = np.array(X_test_seq)\n",
        "\n",
        "# Predict\n",
        "y_pred_scaled = model.predict(X_test_seq)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "y_pred_original = scaler_Y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "# Save results to CSV\n",
        "y_pred_original =pd.DataFrame(y_pred_original)\n",
        "output_df = pd.DataFrame(y_pred_original)\n",
        "output_df.to_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved successfully!\")"
      ],
      "metadata": {
        "id": "NE2nc-nsHWqG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbf273e5-d37b-4ee4-9f20-b5eb78a0b3bf"
      },
      "id": "NE2nc-nsHWqG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (67248, 30, 32)\n",
            "X_test shape: (16812, 30, 32)\n",
            "y_train shape: (67248, 10)\n",
            "y_test shape: (16812, 10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m6,208\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m131,968\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │            \u001b[38;5;34m256\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m16,512\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m16,512\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │            \u001b[38;5;34m256\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m122,944\u001b[0m │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m330\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,968</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">122,944</span> │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321,770\u001b[0m (1.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,770</span> (1.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321,770\u001b[0m (1.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,770</span> (1.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 52ms/step - loss: 0.0973 - mae: 0.1913 - val_loss: 0.0364 - val_mae: 0.1471\n",
            "Epoch 2/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 51ms/step - loss: 0.0263 - mae: 0.1194 - val_loss: 0.0358 - val_mae: 0.1416\n",
            "Epoch 3/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 49ms/step - loss: 0.0246 - mae: 0.1143 - val_loss: 0.0391 - val_mae: 0.1487\n",
            "Epoch 4/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 49ms/step - loss: 0.0238 - mae: 0.1120 - val_loss: 0.0334 - val_mae: 0.1382\n",
            "Epoch 5/50\n",
            "\u001b[1m 384/2102\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 48ms/step - loss: 0.0225 - mae: 0.1086"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c35eae32de4a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# Train the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# ------------------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Plot Training Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Reshape, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ------------------------------- #\n",
        "# Load & Preprocess Data\n",
        "# ------------------------------- #\n",
        "\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "time_steps = 30\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, [\"Avg_Temperature\",\"Avg_Feels_Like_Temperature\",\"Temperature_Range\",\"Feels_Like_Temperature_Range\",\"Radiation\",\"Rain_Amount\",\"Rain_Duration\",\"Wind_Speed\",\"Wind_Direction\",\"Evapotranspiration\"]].values\n",
        "\n",
        "    scaler_X = MinMaxScaler()\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "\n",
        "    scaler_Y = MinMaxScaler()\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "X_seq, Y_seq = np.array(X_seq), np.array(Y_seq)\n",
        "\n",
        "# Split into train-test\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# ------------------------------- #\n",
        "# Define Optuna Optimization\n",
        "# ------------------------------- #\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate):\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
        "    attn_output = Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
        "\n",
        "    ff_output = Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
        "    return LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
        "\n",
        "def objective(trial):\n",
        "    # Hyperparameters\n",
        "    filters = trial.suggest_categorical(\"filters\", [32, 64, 128])\n",
        "    dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
        "    num_heads = trial.suggest_categorical(\"num_heads\", [2, 4, 8])\n",
        "    ff_dim = trial.suggest_categorical(\"ff_dim\", [64, 128, 256])\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "\n",
        "    # Model Input\n",
        "    input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "\n",
        "    # CNN Layers\n",
        "    conv1 = Conv1D(filters=filters, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "    conv2 = Conv1D(filters=filters * 2, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "\n",
        "    new_time_steps = time_steps // 2\n",
        "    transformer_input = Reshape((new_time_steps, conv2.shape[-1]))(conv2)\n",
        "\n",
        "    # Transformer Layer\n",
        "    transformer_output = transformer_encoder(transformer_input, head_size=64, num_heads=num_heads, ff_dim=ff_dim, dropout_rate=dropout_rate)\n",
        "\n",
        "    # Flatten and Dense Layers\n",
        "    flatten = Flatten()(transformer_output)\n",
        "    dense1 = Dense(64, activation='relu')(flatten)\n",
        "    dropout1 = Dropout(dropout_rate)(dense1)\n",
        "    output_layer = Dense(10)(dropout1)\n",
        "\n",
        "    # Compile Model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=RMSprop(learning_rate=learning_rate), loss='mse', metrics=['mae'])\n",
        "\n",
        "    # Train Model\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=batch_size, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "    # Return validation loss\n",
        "    return history.history['val_loss'][-1]\n",
        "\n",
        "# Run Optuna Optimization\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Best Parameters\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weiEY9DoMbHO",
        "outputId": "41e3d689-e26c-446a-9856-65c63cbc3f58"
      },
      "id": "weiEY9DoMbHO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-01 16:44:34,879] A new study created in memory with name: no-name-e2be98f0-229e-425f-b80c-c44fc86aad78\n",
            "<ipython-input-15-6ef3f32dc740>:60: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
            "<ipython-input-15-6ef3f32dc740>:61: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMb1b9plPOIX",
        "outputId": "9d795cc9-df11-4644-9006-775cd3d721c3"
      },
      "id": "aMb1b9plPOIX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LayerNormalization, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "# Define Time Steps\n",
        "time_steps = 30\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "# Normalize Features\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_Y = MinMaxScaler()\n",
        "\n",
        "# Group by Kingdom\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, [\"Avg_Temperature\", \"Radiation\", \"Rain_Amount\", \"Wind_Speed\", \"Wind_Direction\"]].values\n",
        "\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "X_seq, Y_seq = np.array(X_seq), np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# Model Architecture\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
        "    attn_output = tf.keras.layers.Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
        "\n",
        "    ff_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ff_output = tf.keras.layers.Dense(inputs.shape[-1])(ff_output)\n",
        "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
        "\n",
        "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "\n",
        "lstm = LSTM(64, return_sequences=True)(conv2)\n",
        "transformer_output = transformer_encoder(lstm, head_size=64, num_heads=8, ff_dim=128)\n",
        "\n",
        "flatten = Flatten()(transformer_output)\n",
        "dense1 = Dense(64, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(y_train.shape[-1])(dense2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Early Stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=[early_stop])\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Forecasting\n",
        "def smape(y_true, y_pred):\n",
        "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "y_test_original = scaler_Y.inverse_transform(y_test)\n",
        "y_pred_original = scaler_Y.inverse_transform(model.predict(X_test))\n",
        "\n",
        "smape_values = [smape(y_test_original[:, i], y_pred_original[:, i]) for i in range(y_test_original.shape[1])]\n",
        "target_columns = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
        "for i, col in enumerate(target_columns):\n",
        "    print(f\"sMAPE for {col}: {smape_values[i]:.2f}%\")\n",
        "\n",
        "print(f\"Overall sMAPE: {np.mean(smape_values):.2f}%\")\n"
      ],
      "metadata": {
        "id": "T2k7DGTJPQzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9739eb3-19f2-455f-87a8-ca9fc04d9909"
      },
      "id": "T2k7DGTJPQzF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - loss: 0.0481 - mae: 0.1455 - val_loss: 0.0248 - val_mae: 0.1171\n",
            "Epoch 2/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12ms/step - loss: 0.0208 - mae: 0.1043 - val_loss: 0.0247 - val_mae: 0.1146\n",
            "Epoch 3/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - loss: 0.0201 - mae: 0.1016 - val_loss: 0.0235 - val_mae: 0.1126\n",
            "Epoch 4/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 0.0195 - mae: 0.0995 - val_loss: 0.0251 - val_mae: 0.1168\n",
            "Epoch 5/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - loss: 0.0189 - mae: 0.0976 - val_loss: 0.0246 - val_mae: 0.1149\n",
            "Epoch 6/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0182 - mae: 0.0957 - val_loss: 0.0238 - val_mae: 0.1122\n",
            "Epoch 7/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0178 - mae: 0.0942 - val_loss: 0.0227 - val_mae: 0.1079\n",
            "Epoch 8/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0170 - mae: 0.0918 - val_loss: 0.0237 - val_mae: 0.1108\n",
            "Epoch 9/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 0.0163 - mae: 0.0896 - val_loss: 0.0221 - val_mae: 0.1075\n",
            "Epoch 10/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - loss: 0.0156 - mae: 0.0875 - val_loss: 0.0212 - val_mae: 0.1054\n",
            "Epoch 11/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 0.0151 - mae: 0.0860 - val_loss: 0.0233 - val_mae: 0.1106\n",
            "Epoch 12/100\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - loss: 0.0146 - mae: 0.0841 - val_loss: 0.0239 - val_mae: 0.1112\n",
            "Epoch 13/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LayerNormalization, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "# Define Time Steps\n",
        "time_steps = 30\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "# Normalize Features\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_Y = MinMaxScaler()\n",
        "\n",
        "# Group by Kingdom\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, [\"Avg_Temperature\",\"Temperature_Range\",\"Radiation\",\"Rain_Amount\",\"Rain_Duration\",\"Wind_Speed\",\"Wind_Direction\",\"Evapotranspiration\"]].values\n",
        "\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "X_seq, Y_seq = np.array(X_seq), np.array(Y_seq)\n",
        "\n",
        "# Train-Test Split\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# Model Architecture\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
        "    attn_output = tf.keras.layers.Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
        "\n",
        "    ff_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ff_output = tf.keras.layers.Dense(inputs.shape[-1])(ff_output)\n",
        "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
        "\n",
        "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "\n",
        "lstm = LSTM(64, return_sequences=True)(conv2)\n",
        "transformer_output = transformer_encoder(lstm, head_size=64, num_heads=8, ff_dim=128)\n",
        "\n",
        "flatten = Flatten()(transformer_output)\n",
        "dense1 = Dense(64, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(y_train.shape[-1])(dense2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Early Stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, callbacks=[early_stop])\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Forecasting\n",
        "def smape(y_true, y_pred):\n",
        "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "y_test_original = scaler_Y.inverse_transform(y_test)\n",
        "y_pred_original = scaler_Y.inverse_transform(model.predict(X_test))\n",
        "\n",
        "smape_values = [smape(y_test_original[:, i], y_pred_original[:, i]) for i in range(y_test_original.shape[1])]\n",
        "target_columns = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
        "for i, col in enumerate(target_columns):\n",
        "    print(f\"sMAPE for {col}: {smape_values[i]:.2f}%\")\n",
        "\n",
        "print(f\"Overall sMAPE: {np.mean(smape_values):.2f}%\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the test dataset\n",
        "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
        "\n",
        "# Apply the same preprocessing as the training data\n",
        "test_df.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "test_df = pd.get_dummies(test_df, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "# Ensure all training features exist in test data\n",
        "missing_cols = set(df.columns) - set(test_df.columns)\n",
        "for col in missing_cols:\n",
        "    test_df[col] = 0  # Add missing one-hot encoded columns\n",
        "\n",
        "# Select feature columns (same as training)\n",
        "feature_cols = ['Year', 'Month', 'Day'] + [col for col in test_df.columns if 'kingdom' in col]\n",
        "test_X = test_df[feature_cols].values\n",
        "\n",
        "# Normalize test data using the same scaler\n",
        "test_X = scaler_X.transform(test_X)\n",
        "\n",
        "# Reshape for model input (if sequences are needed)\n",
        "X_test_seq = []\n",
        "for i in range(len(test_X) - time_steps):\n",
        "    X_test_seq.append(test_X[i:i+time_steps])\n",
        "X_test_seq = np.array(X_test_seq)\n",
        "\n",
        "# Predict\n",
        "y_pred_scaled = model.predict(X_test_seq)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "y_pred_original = scaler_Y.inverse_transform(y_pred_scaled)\n",
        "\n",
        "# Save results to CSV\n",
        "y_pred_original =pd.DataFrame(y_pred_original)\n",
        "output_df = pd.DataFrame(y_pred_original)\n",
        "output_df.to_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved successfully!\")"
      ],
      "metadata": {
        "id": "M9BhF-cdYClR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f933f190-a591-479a-dd6a-37cccea7f707"
      },
      "id": "M9BhF-cdYClR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
            "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
            "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - loss: 0.0564 - mae: 0.1676 - val_loss: 0.0355 - val_mae: 0.1379\n",
            "Epoch 2/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0243 - mae: 0.1123 - val_loss: 0.0355 - val_mae: 0.1398\n",
            "Epoch 3/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 0.0229 - mae: 0.1087 - val_loss: 0.0334 - val_mae: 0.1333\n",
            "Epoch 4/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0218 - mae: 0.1057 - val_loss: 0.0344 - val_mae: 0.1383\n",
            "Epoch 5/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0211 - mae: 0.1035 - val_loss: 0.0335 - val_mae: 0.1344\n",
            "Epoch 6/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0202 - mae: 0.1008 - val_loss: 0.0327 - val_mae: 0.1316\n",
            "Epoch 7/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0197 - mae: 0.0993 - val_loss: 0.0327 - val_mae: 0.1323\n",
            "Epoch 8/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0188 - mae: 0.0968 - val_loss: 0.0336 - val_mae: 0.1317\n",
            "Epoch 9/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0184 - mae: 0.0954 - val_loss: 0.0317 - val_mae: 0.1283\n",
            "Epoch 10/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - loss: 0.0175 - mae: 0.0929 - val_loss: 0.0321 - val_mae: 0.1300\n",
            "Epoch 11/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16ms/step - loss: 0.0172 - mae: 0.0919 - val_loss: 0.0321 - val_mae: 0.1296\n",
            "Epoch 12/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 0.0169 - mae: 0.0910 - val_loss: 0.0310 - val_mae: 0.1280\n",
            "Epoch 13/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0166 - mae: 0.0901 - val_loss: 0.0319 - val_mae: 0.1282\n",
            "Epoch 14/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0161 - mae: 0.0884 - val_loss: 0.0303 - val_mae: 0.1252\n",
            "Epoch 15/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0157 - mae: 0.0870 - val_loss: 0.0300 - val_mae: 0.1242\n",
            "Epoch 16/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0157 - mae: 0.0870 - val_loss: 0.0303 - val_mae: 0.1243\n",
            "Epoch 17/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0150 - mae: 0.0850 - val_loss: 0.0304 - val_mae: 0.1256\n",
            "Epoch 18/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0148 - mae: 0.0846 - val_loss: 0.0300 - val_mae: 0.1228\n",
            "Epoch 19/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0146 - mae: 0.0837 - val_loss: 0.0297 - val_mae: 0.1231\n",
            "Epoch 20/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0144 - mae: 0.0829 - val_loss: 0.0317 - val_mae: 0.1258\n",
            "Epoch 21/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0141 - mae: 0.0821 - val_loss: 0.0296 - val_mae: 0.1223\n",
            "Epoch 22/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0141 - mae: 0.0822 - val_loss: 0.0300 - val_mae: 0.1217\n",
            "Epoch 23/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0140 - mae: 0.0817 - val_loss: 0.0304 - val_mae: 0.1231\n",
            "Epoch 24/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 0.0138 - mae: 0.0811 - val_loss: 0.0300 - val_mae: 0.1218\n",
            "Epoch 25/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0137 - mae: 0.0807 - val_loss: 0.0293 - val_mae: 0.1204\n",
            "Epoch 26/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0136 - mae: 0.0804 - val_loss: 0.0296 - val_mae: 0.1218\n",
            "Epoch 27/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0135 - mae: 0.0799 - val_loss: 0.0308 - val_mae: 0.1242\n",
            "Epoch 28/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0134 - mae: 0.0795 - val_loss: 0.0296 - val_mae: 0.1216\n",
            "Epoch 29/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0135 - mae: 0.0796 - val_loss: 0.0292 - val_mae: 0.1199\n",
            "Epoch 30/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0132 - mae: 0.0788 - val_loss: 0.0288 - val_mae: 0.1198\n",
            "Epoch 31/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.0131 - mae: 0.0786 - val_loss: 0.0288 - val_mae: 0.1186\n",
            "Epoch 32/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 0.0129 - mae: 0.0779 - val_loss: 0.0289 - val_mae: 0.1192\n",
            "Epoch 33/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.0129 - mae: 0.0778 - val_loss: 0.0304 - val_mae: 0.1236\n",
            "Epoch 34/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 0.0128 - mae: 0.0776 - val_loss: 0.0280 - val_mae: 0.1188\n",
            "Epoch 35/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0128 - mae: 0.0774 - val_loss: 0.0299 - val_mae: 0.1208\n",
            "Epoch 36/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0129 - mae: 0.0776 - val_loss: 0.0292 - val_mae: 0.1201\n",
            "Epoch 37/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.0127 - mae: 0.0768 - val_loss: 0.0295 - val_mae: 0.1192\n",
            "Epoch 38/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 0.0127 - mae: 0.0766 - val_loss: 0.0288 - val_mae: 0.1178\n",
            "Epoch 39/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0124 - mae: 0.0760 - val_loss: 0.0299 - val_mae: 0.1210\n",
            "Epoch 40/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0125 - mae: 0.0761 - val_loss: 0.0299 - val_mae: 0.1210\n",
            "Epoch 41/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0125 - mae: 0.0762 - val_loss: 0.0301 - val_mae: 0.1221\n",
            "Epoch 42/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0123 - mae: 0.0756 - val_loss: 0.0302 - val_mae: 0.1209\n",
            "Epoch 43/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0123 - mae: 0.0755 - val_loss: 0.0294 - val_mae: 0.1194\n",
            "Epoch 44/50\n",
            "\u001b[1m1365/1365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0123 - mae: 0.0752 - val_loss: 0.0294 - val_mae: 0.1193\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "sMAPE for Avg_Temperature: 4.69%\n",
            "sMAPE for Radiation: 29.19%\n",
            "sMAPE for Rain_Amount: 12.16%\n",
            "sMAPE for Wind_Speed: 120.37%\n",
            "sMAPE for Wind_Direction: 99.60%\n",
            "Overall sMAPE: 40.75%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-17feec8de717>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Load the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# Apply the same preprocessing as the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " Save results to CSV\n",
        "y_pred_original =pd.DataFrame(y_pred_original)\n",
        "output_df = pd.DataFrame(y_pred_original)\n",
        "output_df.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved successfully!\")"
      ],
      "metadata": {
        "id": "HhkpRKBCeUXd"
      },
      "id": "HhkpRKBCeUXd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM,\n",
        "                                     LayerNormalization, MultiHeadAttention, Reshape)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"cleaned_data.csv\")\n",
        "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
        "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)\n",
        "\n",
        "time_steps = 30\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_Y = MinMaxScaler()\n",
        "\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, ['Avg_Temperature','Avg_Feels_Like_Temperature','Temperature_Range','Feels_Like_Temperature_Range','Radiation','Rain_Amount,Rain_Duration','Wind_Speed','Wind_Direction','Evapotranspiration']].values\n",
        "\n",
        "    group_X = scaler_X.fit_transform(group_X)\n",
        "    group_Y = scaler_Y.fit_transform(group_Y)\n",
        "\n",
        "    for i in range(len(group_X) - time_steps):\n",
        "        X_seq.append(group_X[i:i+time_steps])\n",
        "        Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "X_seq, Y_seq = np.array(X_seq), np.array(Y_seq)\n",
        "\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
        "    attn_output = Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
        "\n",
        "    ff_output = Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
        "    return LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
        "\n",
        "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "conv2 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(pool1)\n",
        "\n",
        "lstm = LSTM(64, return_sequences=True)(conv2)\n",
        "transformer_output = transformer_encoder(lstm, head_size=64, num_heads=8, ff_dim=128)\n",
        "\n",
        "flatten = Flatten()(transformer_output)\n",
        "dense1 = Dense(64, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(32, activation='relu')(dropout1)\n",
        "output_layer = Dense(y_train.shape[-1])(dense2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L7U-fxc-iTH9",
        "outputId": "9b221abb-c30d-44f3-b2a2-3476e1f55ea1"
      },
      "id": "L7U-fxc-iTH9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0520 - mae: 0.1594 - val_loss: 0.0421 - val_mae: 0.1533\n",
            "Epoch 2/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0261 - mae: 0.1171 - val_loss: 0.0366 - val_mae: 0.1449\n",
            "Epoch 3/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.0251 - mae: 0.1142 - val_loss: 0.0369 - val_mae: 0.1455\n",
            "Epoch 4/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 0.0246 - mae: 0.1126 - val_loss: 0.0354 - val_mae: 0.1416\n",
            "Epoch 5/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0237 - mae: 0.1100 - val_loss: 0.0348 - val_mae: 0.1370\n",
            "Epoch 6/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0233 - mae: 0.1092 - val_loss: 0.0372 - val_mae: 0.1428\n",
            "Epoch 7/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0230 - mae: 0.1083 - val_loss: 0.0390 - val_mae: 0.1490\n",
            "Epoch 8/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 0.0223 - mae: 0.1065 - val_loss: 0.0337 - val_mae: 0.1358\n",
            "Epoch 9/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.0217 - mae: 0.1050 - val_loss: 0.0402 - val_mae: 0.1505\n",
            "Epoch 10/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0211 - mae: 0.1033 - val_loss: 0.0353 - val_mae: 0.1399\n",
            "Epoch 11/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0207 - mae: 0.1019 - val_loss: 0.0344 - val_mae: 0.1383\n",
            "Epoch 12/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0202 - mae: 0.1006 - val_loss: 0.0343 - val_mae: 0.1367\n",
            "Epoch 13/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0194 - mae: 0.0984 - val_loss: 0.0342 - val_mae: 0.1356\n",
            "Epoch 14/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0190 - mae: 0.0972 - val_loss: 0.0344 - val_mae: 0.1344\n",
            "Epoch 15/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0182 - mae: 0.0950 - val_loss: 0.0309 - val_mae: 0.1275\n",
            "Epoch 16/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0179 - mae: 0.0940 - val_loss: 0.0352 - val_mae: 0.1332\n",
            "Epoch 17/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0923 - val_loss: 0.0337 - val_mae: 0.1320\n",
            "Epoch 18/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0169 - mae: 0.0910 - val_loss: 0.0307 - val_mae: 0.1235\n",
            "Epoch 19/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0166 - mae: 0.0899 - val_loss: 0.0316 - val_mae: 0.1261\n",
            "Epoch 20/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0888 - val_loss: 0.0326 - val_mae: 0.1288\n",
            "Epoch 21/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0158 - mae: 0.0876 - val_loss: 0.0340 - val_mae: 0.1320\n",
            "Epoch 22/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0155 - mae: 0.0868 - val_loss: 0.0324 - val_mae: 0.1285\n",
            "Epoch 23/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.0861 - val_loss: 0.0320 - val_mae: 0.1267\n",
            "Epoch 24/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0853 - val_loss: 0.0314 - val_mae: 0.1247\n",
            "Epoch 25/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0149 - mae: 0.0847 - val_loss: 0.0321 - val_mae: 0.1275\n",
            "Epoch 26/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0839 - val_loss: 0.0325 - val_mae: 0.1271\n",
            "Epoch 27/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0832 - val_loss: 0.0307 - val_mae: 0.1240\n",
            "Epoch 28/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - loss: 0.0143 - mae: 0.0827 - val_loss: 0.0310 - val_mae: 0.1229\n",
            "Epoch 29/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 0.0140 - mae: 0.0819 - val_loss: 0.0332 - val_mae: 0.1289\n",
            "Epoch 30/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - loss: 0.0139 - mae: 0.0815 - val_loss: 0.0324 - val_mae: 0.1250\n",
            "Epoch 31/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 0.0136 - mae: 0.0805 - val_loss: 0.0303 - val_mae: 0.1215\n",
            "Epoch 32/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 0.0137 - mae: 0.0804 - val_loss: 0.0299 - val_mae: 0.1200\n",
            "Epoch 33/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0799 - val_loss: 0.0308 - val_mae: 0.1226\n",
            "Epoch 34/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0133 - mae: 0.0793 - val_loss: 0.0300 - val_mae: 0.1201\n",
            "Epoch 35/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0133 - mae: 0.0794 - val_loss: 0.0306 - val_mae: 0.1222\n",
            "Epoch 36/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0131 - mae: 0.0788 - val_loss: 0.0310 - val_mae: 0.1215\n",
            "Epoch 37/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 14ms/step - loss: 0.0130 - mae: 0.0780 - val_loss: 0.0296 - val_mae: 0.1181\n",
            "Epoch 38/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - loss: 0.0129 - mae: 0.0780 - val_loss: 0.0304 - val_mae: 0.1203\n",
            "Epoch 39/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0776 - val_loss: 0.0284 - val_mae: 0.1160\n",
            "Epoch 40/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 12ms/step - loss: 0.0127 - mae: 0.0774 - val_loss: 0.0302 - val_mae: 0.1205\n",
            "Epoch 41/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0773 - val_loss: 0.0300 - val_mae: 0.1186\n",
            "Epoch 42/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0126 - mae: 0.0769 - val_loss: 0.0287 - val_mae: 0.1159\n",
            "Epoch 43/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0125 - mae: 0.0766 - val_loss: 0.0303 - val_mae: 0.1207\n",
            "Epoch 44/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 0.0124 - mae: 0.0763 - val_loss: 0.0303 - val_mae: 0.1193\n",
            "Epoch 45/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0125 - mae: 0.0764 - val_loss: 0.0308 - val_mae: 0.1209\n",
            "Epoch 46/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0758 - val_loss: 0.0299 - val_mae: 0.1190\n",
            "Epoch 47/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0124 - mae: 0.0761 - val_loss: 0.0306 - val_mae: 0.1190\n",
            "Epoch 48/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0754 - val_loss: 0.0296 - val_mae: 0.1185\n",
            "Epoch 49/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0755 - val_loss: 0.0290 - val_mae: 0.1178\n",
            "Epoch 50/50\n",
            "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0751 - val_loss: 0.0293 - val_mae: 0.1189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_X = MinMaxScaler()\n",
        "scaler_Y = MinMaxScaler()\n",
        "\n",
        "X_seq, Y_seq = [], []\n",
        "\n",
        "for kingdom, group in df1.groupby('kingdom'):\n",
        "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
        "    group_Y = group.loc[:, ['Avg_Temperature', 'Avg_Feels_Like_Temperature', 'Temperature_Range',\n",
        "                            'Feels_Like_Temperature_Range', 'Radiation', 'Rain_Amount',\n",
        "                            'Rain_Duration', 'Wind_Speed', 'Wind_Direction', 'Evapotranspiration']].values\n",
        "\n",
        "    if len(group_X) > 0:  # Avoid empty groups\n",
        "        scaler_X.fit(group_X)  # Fit only once per group\n",
        "        scaler_Y.fit(group_Y)  # Ensure scaler_Y is fitted\n",
        "\n",
        "        group_X = scaler_X.transform(group_X)\n",
        "        group_Y = scaler_Y.transform(group_Y)\n",
        "\n",
        "        for i in range(len(group_X) - time_steps):\n",
        "            X_seq.append(group_X[i:i+time_steps])\n",
        "            Y_seq.append(group_Y[i+time_steps])\n",
        "\n",
        "X_seq, Y_seq = np.array(X_seq), np.array(Y_seq)\n",
        "\n",
        "split = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
        "\n",
        "# Ensure the scaler is properly fitted before inverse transforming\n",
        "y_test_original = scaler_Y.inverse_transform(y_test)\n",
        "y_pred_original = scaler_Y.inverse_transform(model.predict(X_test))\n",
        "def smape(y_true, y_pred):\n",
        "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))\n",
        "\n",
        "smape_values = [smape(y_test_original[:, i], y_pred_original[:, i]) for i in range(y_test_original.shape[1])]\n",
        "\n",
        "for i, col in enumerate(['Avg_Temperature', 'Avg_Feels_Like_Temperature', 'Temperature_Range',\n",
        "                            'Feels_Like_Temperature_Range', 'Radiation', 'Rain_Amount',\n",
        "                            'Rain_Duration', 'Wind_Speed', 'Wind_Direction', 'Evapotranspiration']):\n",
        "    print(f\"sMAPE for {col}: {smape_values[i]:.2f}%\")\n",
        "\n",
        "average_smape = np.mean(smape_values)\n",
        "print(f\"Overall sMAPE: {average_smape:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "7L7L2jGvkENG",
        "outputId": "816cb373-20f1-4172-d024-3d73e889bd7a"
      },
      "id": "7L7L2jGvkENG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (16812,8) (10,) (16812,8) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d24b0c29ff77>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Ensure the scaler is properly fitted before inverse transforming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0my_test_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0my_pred_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    579\u001b[0m         )\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (16812,8) (10,) (16812,8) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MPeHdmhFxeK5"
      },
      "id": "MPeHdmhFxeK5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}